(window.webpackJsonp=window.webpackJsonp||[]).push([[3],{1056:function(s,e,a){s.exports=a.p+"assets/img/150.48b0ede2.png"},1057:function(s,e,a){s.exports=a.p+"assets/img/151.65c9e5ee.png"},1058:function(s,e,a){s.exports=a.p+"assets/img/152.313bf865.png"},1059:function(s,e,a){s.exports=a.p+"assets/img/153.daf2b43e.png"},1060:function(s,e,a){s.exports=a.p+"assets/img/154.8c6e80a3.png"},1061:function(s,e,a){s.exports=a.p+"assets/img/155.0adae41b.png"},1062:function(s,e,a){s.exports=a.p+"assets/img/156.43a1ca4a.png"},1063:function(s,e,a){s.exports=a.p+"assets/img/157.259596b5.png"},1064:function(s,e,a){s.exports=a.p+"assets/img/158.883a284e.png"},1065:function(s,e,a){s.exports=a.p+"assets/img/159.3d7df537.png"},1066:function(s,e,a){s.exports=a.p+"assets/img/160.9594d3e6.png"},1067:function(s,e,a){s.exports=a.p+"assets/img/161.b8505ac3.png"},1068:function(s,e,a){s.exports=a.p+"assets/img/162.038032a9.png"},1069:function(s,e,a){s.exports=a.p+"assets/img/163.970035f9.png"},1070:function(s,e,a){s.exports=a.p+"assets/img/164.0d6f804c.png"},1071:function(s,e,a){s.exports=a.p+"assets/img/165.d50849d9.png"},1072:function(s,e,a){s.exports=a.p+"assets/img/166.063fcc85.png"},1073:function(s,e,a){s.exports=a.p+"assets/img/167.634a323c.png"},1074:function(s,e,a){s.exports=a.p+"assets/img/168.e71e0cf4.png"},1075:function(s,e,a){s.exports=a.p+"assets/img/169.f26cc2cd.png"},1076:function(s,e,a){s.exports=a.p+"assets/img/170.86cc0712.png"},1077:function(s,e,a){s.exports=a.p+"assets/img/171.e1457246.png"},1078:function(s,e,a){s.exports=a.p+"assets/img/172.67dab0bf.png"},1079:function(s,e,a){s.exports=a.p+"assets/img/173.46969319.png"},1080:function(s,e,a){s.exports=a.p+"assets/img/174.f2ae162f.png"},1081:function(s,e,a){s.exports=a.p+"assets/img/175.3fe97255.png"},1082:function(s,e,a){s.exports=a.p+"assets/img/176.6f6135be.png"},1083:function(s,e,a){s.exports=a.p+"assets/img/177.3147e158.png"},1084:function(s,e,a){s.exports=a.p+"assets/img/178.223d3e9f.png"},1085:function(s,e,a){s.exports=a.p+"assets/img/179.cfb36d67.png"},1086:function(s,e,a){s.exports=a.p+"assets/img/180.b15c8ca4.png"},1087:function(s,e,a){s.exports=a.p+"assets/img/181.159878f3.png"},1088:function(s,e,a){s.exports=a.p+"assets/img/182.8996ff9c.png"},1089:function(s,e,a){s.exports=a.p+"assets/img/183.19932412.png"},1090:function(s,e,a){s.exports=a.p+"assets/img/184.86bb991b.png"},1091:function(s,e,a){s.exports=a.p+"assets/img/185.9a6600e9.png"},1092:function(s,e,a){s.exports=a.p+"assets/img/186.64ac3786.png"},1093:function(s,e,a){s.exports=a.p+"assets/img/187.ca997617.png"},1094:function(s,e,a){s.exports=a.p+"assets/img/188.7c6a158e.png"},1095:function(s,e,a){s.exports=a.p+"assets/img/189.5374a7db.png"},1096:function(s,e,a){s.exports=a.p+"assets/img/190.bc77595b.png"},1097:function(s,e,a){s.exports=a.p+"assets/img/191.acd4b441.png"},1098:function(s,e,a){s.exports=a.p+"assets/img/192.1b706b9c.png"},1099:function(s,e,a){s.exports=a.p+"assets/img/193.bf712138.png"},1100:function(s,e,a){s.exports=a.p+"assets/img/194.b3582e4a.png"},1101:function(s,e,a){s.exports=a.p+"assets/img/195.bc12c9b8.png"},2705:function(s,e,a){"use strict";a.r(e);var t=a(2),r=Object(t.a)({},(function(){var s=this,e=s.$createElement,t=s._self._c||e;return t("ContentSlotsDistributor",{attrs:{"slot-key":s.$parent.slotKey}},[t("h2",{attrs:{id:"安装-mysql-主从复制"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#安装-mysql-主从复制"}},[s._v("#")]),s._v(" 安装 mysql 主从复制")]),s._v(" "),t("p",[s._v("2.1.1.安装 mysql 主从复制\n·主从复制原理\n·默认你懂\n·主从搭建步骤\n·新建主服务器容器实例 3307")]),s._v(" "),t("p",[s._v("docker run -p 3307:3306 --name mysql-master "),t("br"),s._v("\n-v /mydata/mysql-master/log:/var/log/mysql "),t("br"),s._v("\n-v /mydata/mysql-master/data:/var/lib/mysql "),t("br"),s._v("\n-v /mydata/mysql-master/conf:/etc/mysql "),t("br"),s._v("\n-e MYSQL_ROOT_PASSWORD=root  "),t("br"),s._v("\n-d mysql:5.7")]),s._v(" "),t("p",[s._v("·进入/mydata/mysql-master/conf 目录下新建 my.cnf\n·vim my.cnf\n[mysqld]")]),s._v(" "),t("h2",{attrs:{id:"设置-server-id-同一局域网中需要唯一"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#设置-server-id-同一局域网中需要唯一"}},[s._v("#")]),s._v(" 设置 server_id，同一局域网中需要唯一")]),s._v(" "),t("p",[s._v("server_id=101")]),s._v(" "),t("h2",{attrs:{id:"指定不需要同步的数据库名称"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#指定不需要同步的数据库名称"}},[s._v("#")]),s._v(" 指定不需要同步的数据库名称")]),s._v(" "),t("p",[s._v("binlog-ignore-db=mysql")]),s._v(" "),t("h2",{attrs:{id:"开启二进制日志功能"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#开启二进制日志功能"}},[s._v("#")]),s._v(" 开启二进制日志功能")]),s._v(" "),t("p",[s._v("log-bin=mall-mysql-bin")]),s._v(" "),t("h2",{attrs:{id:"设置二进制日志使用内存大小-事务"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#设置二进制日志使用内存大小-事务"}},[s._v("#")]),s._v(" 设置二进制日志使用内存大小（事务）")]),s._v(" "),t("p",[s._v("binlog_cache_size=1M")]),s._v(" "),t("h2",{attrs:{id:"设置使用的二进制日志格式-mixed-statement-row"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#设置使用的二进制日志格式-mixed-statement-row"}},[s._v("#")]),s._v(" 设置使用的二进制日志格式（mixed,statement,row）")]),s._v(" "),t("p",[s._v("binlog_format=mixed")]),s._v(" "),t("h2",{attrs:{id:"二进制日志过期清理时间。默认值为-0-表示不自动清理。"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#二进制日志过期清理时间。默认值为-0-表示不自动清理。"}},[s._v("#")]),s._v(" 二进制日志过期清理时间。默认值为 0，表示不自动清理。")]),s._v(" "),t("p",[s._v("expire_logs_days=7")]),s._v(" "),t("h2",{attrs:{id:"跳过主从复制中遇到的所有错误或指定类型的错误-避免-slave-端复制中断。"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#跳过主从复制中遇到的所有错误或指定类型的错误-避免-slave-端复制中断。"}},[s._v("#")]),s._v(" 跳过主从复制中遇到的所有错误或指定类型的错误，避免 slave 端复制中断。")]),s._v(" "),t("h2",{attrs:{id:"如-1062-错误是指一些主键重复-1032-错误是因为主从数据库数据不一致"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#如-1062-错误是指一些主键重复-1032-错误是因为主从数据库数据不一致"}},[s._v("#")]),s._v(" 如：1062 错误是指一些主键重复，1032 错误是因为主从数据库数据不一致")]),s._v(" "),t("p",[s._v("slave_skip_errors=1062")]),s._v(" "),t("p",[s._v("·修改完配置后重启 master 实例\n·docker restart mysql-master\n·进入 mysql-master 容器\n·docker exec -it mysql-master /bin/bash\n·mysql -uroot -proot\n·master 容器实例内创建数据同步用户\n·CREATE USER 'slave'@'%' IDENTIFIED BY '123456';\n·GRANT REPLICATION SLAVE, REPLICATION CLIENT ON "),t("em",[s._v(".")]),s._v(" TO 'slave'@'%';\n·新建从服务器容器实例 3308")]),s._v(" "),t("p",[s._v("docker run -p 3308:3306 --name mysql-slave "),t("br"),s._v("\n-v /mydata/mysql-slave/log:/var/log/mysql "),t("br"),s._v("\n-v /mydata/mysql-slave/data:/var/lib/mysql "),t("br"),s._v("\n-v /mydata/mysql-slave/conf:/etc/mysql "),t("br"),s._v("\n-e MYSQL_ROOT_PASSWORD=root  "),t("br"),s._v("\n-d mysql:5.7")]),s._v(" "),t("p",[s._v("·进入/mydata/mysql-slave/conf 目录下新建 my.cnf\n·vim my.cnf")]),s._v(" "),t("p",[s._v("[mysqld]")]),s._v(" "),t("h2",{attrs:{id:"设置-server-id-同一局域网中需要唯一-2"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#设置-server-id-同一局域网中需要唯一-2"}},[s._v("#")]),s._v(" 设置 server_id，同一局域网中需要唯一")]),s._v(" "),t("p",[s._v("server_id=102")]),s._v(" "),t("h2",{attrs:{id:"指定不需要同步的数据库名称-2"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#指定不需要同步的数据库名称-2"}},[s._v("#")]),s._v(" 指定不需要同步的数据库名称")]),s._v(" "),t("p",[s._v("binlog-ignore-db=mysql")]),s._v(" "),t("h2",{attrs:{id:"开启二进制日志功能-以备-slave-作为其它数据库实例的-master-时使用"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#开启二进制日志功能-以备-slave-作为其它数据库实例的-master-时使用"}},[s._v("#")]),s._v(" 开启二进制日志功能，以备 Slave 作为其它数据库实例的 Master 时使用")]),s._v(" "),t("p",[s._v("log-bin=mall-mysql-slave1-bin")]),s._v(" "),t("h2",{attrs:{id:"设置二进制日志使用内存大小-事务-2"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#设置二进制日志使用内存大小-事务-2"}},[s._v("#")]),s._v(" 设置二进制日志使用内存大小（事务）")]),s._v(" "),t("p",[s._v("binlog_cache_size=1M")]),s._v(" "),t("h2",{attrs:{id:"设置使用的二进制日志格式-mixed-statement-row-2"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#设置使用的二进制日志格式-mixed-statement-row-2"}},[s._v("#")]),s._v(" 设置使用的二进制日志格式（mixed,statement,row）")]),s._v(" "),t("p",[s._v("binlog_format=mixed")]),s._v(" "),t("h2",{attrs:{id:"二进制日志过期清理时间。默认值为-0-表示不自动清理。-2"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#二进制日志过期清理时间。默认值为-0-表示不自动清理。-2"}},[s._v("#")]),s._v(" 二进制日志过期清理时间。默认值为 0，表示不自动清理。")]),s._v(" "),t("p",[s._v("expire_logs_days=7")]),s._v(" "),t("h2",{attrs:{id:"跳过主从复制中遇到的所有错误或指定类型的错误-避免-slave-端复制中断。-2"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#跳过主从复制中遇到的所有错误或指定类型的错误-避免-slave-端复制中断。-2"}},[s._v("#")]),s._v(" 跳过主从复制中遇到的所有错误或指定类型的错误，避免 slave 端复制中断。")]),s._v(" "),t("h2",{attrs:{id:"如-1062-错误是指一些主键重复-1032-错误是因为主从数据库数据不一致-2"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#如-1062-错误是指一些主键重复-1032-错误是因为主从数据库数据不一致-2"}},[s._v("#")]),s._v(" 如：1062 错误是指一些主键重复，1032 错误是因为主从数据库数据不一致")]),s._v(" "),t("p",[s._v("slave_skip_errors=1062")]),s._v(" "),t("h2",{attrs:{id:"relay-log-配置中继日志"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#relay-log-配置中继日志"}},[s._v("#")]),s._v(" relay_log 配置中继日志")]),s._v(" "),t("p",[s._v("relay_log=mall-mysql-relay-bin")]),s._v(" "),t("h2",{attrs:{id:"log-slave-updates-表示-slave-将复制事件写进自己的二进制日志"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#log-slave-updates-表示-slave-将复制事件写进自己的二进制日志"}},[s._v("#")]),s._v(" log_slave_updates 表示 slave 将复制事件写进自己的二进制日志")]),s._v(" "),t("p",[s._v("log_slave_updates=1")]),s._v(" "),t("h2",{attrs:{id:"slave-设置为只读-具有-super-权限的用户除外"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#slave-设置为只读-具有-super-权限的用户除外"}},[s._v("#")]),s._v(" slave 设置为只读（具有 super 权限的用户除外）")]),s._v(" "),t("p",[s._v("read_only=1\n·修改完配置后重启 slave 实例\n·docker restart mysql-slave\n·在主数据库中查看主从同步状态\n·show master status;\n·进入 mysql-slave 容器\n·docker exec -it mysql-slave /bin/bash\n·mysql -uroot -proot\n·在从数据库中配置主从复制")]),s._v(" "),t("p",[s._v("change master to master_host='宿主机 ip', master_user='slave', master_password='123456', master_port=3307, master_log_file='mall-mysql-bin.000001', master_log_pos=617, master_connect_retry=30;")]),s._v(" "),t("p",[t("img",{attrs:{src:a(1056),alt:""}})]),s._v(" "),t("p",[s._v("·主从复制命令参数说明\nmaster_host：主数据库的 IP 地址；\nmaster_port：主数据库的运行端口；\nmaster_user：在主数据库创建的用于同步数据的用户账号；\nmaster_password：在主数据库创建的用于同步数据的用户密码；\nmaster_log_file：指定从数据库要复制数据的日志文件，通过查看主数据的状态，获取 File 参数；\nmaster_log_pos：指定从数据库从哪个位置开始复制数据，通过查看主数据的状态，获取 Position 参数；\nmaster_connect_retry：连接失败重试的时间间隔，单位为秒。")]),s._v(" "),t("p",[t("img",{attrs:{src:a(1057),alt:""}})]),s._v(" "),t("p",[s._v("·在从数据库中查看主从同步状态\n·show slave status \\G;")]),s._v(" "),t("p",[t("img",{attrs:{src:a(1058),alt:""}})]),s._v(" "),t("p",[t("img",{attrs:{src:a(1059),alt:""}})]),s._v(" "),t("p",[s._v("·在从数据库中开启主从同步")]),s._v(" "),t("p",[s._v("·查看从数据库状态发现已经同步")]),s._v(" "),t("p",[t("img",{attrs:{src:a(1060),alt:""}})]),s._v(" "),t("p",[s._v("·主从复制测试\n·主机新建库-使用库-新建表-插入数据，ok\n·从机使用库-查看记录，ok")]),s._v(" "),t("h2",{attrs:{id:"安装-redis-集群-大厂面试题第-4-季-分布式存储案例真题"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#安装-redis-集群-大厂面试题第-4-季-分布式存储案例真题"}},[s._v("#")]),s._v(" 安装 redis 集群(大厂面试题第 4 季-分布式存储案例真题)")]),s._v(" "),t("p",[s._v("·cluster(集群)模式-docker 版 哈希槽分区进行亿级数据存储\n·面试题\n·1~2 亿条数据需要缓存，请问如何设计这个存储案例\n·回答\n·单机单台 100%不可能，肯定是分布式存储，用 redis 如何落地？\n·上述问题阿里 P6~P7 工程案例和场景设计类必考题目， 一般业界有 3 种解决方案\n·哈希取余分区")]),s._v(" "),t("p",[t("img",{attrs:{src:a(1061),alt:""}})]),s._v(" "),t("p",[s._v("2 亿条记录就是 2 亿个 k,v，我们单机不行必须要分布式多机，假设有 3 台机器构成一个集群，用户每次读写操作都是根据公式：\nhash(key) % N 个机器台数，计算出哈希值，用来决定数据映射到哪一个节点上。")]),s._v(" "),t("p",[s._v("优点：\n  简单粗暴，直接有效，只需要预估好数据规划好节点，例如 3 台、8 台、10 台，就能保证一段时间的数据支撑。使用 Hash 算法让固定的一部分请求落到同一台服务器上，这样每台服务器固定处理一部分请求（并维护这些请求的信息），起到负载均衡+分而治之的作用。")]),s._v(" "),t("p",[s._v("缺点：\n   原来规划好的节点，进行扩容或者缩容就比较麻烦了额，不管扩缩，每次数据变动导致节点有变动，映射关系需要重新进行计算，在服务器个数固定不变时没有问题，如果需要弹性扩容或故障停机的情况下，原来的取模公式就会发生变化：Hash(key)/3 会变成 Hash(key) /?。此时地址经过取余运算的结果将发生很大变化，根据公式获取的服务器也会变得不可控。\n某个 redis 机器宕机了，由于台数数量变化，会导致 hash 取余全部数据重新洗牌。")]),s._v(" "),t("p",[s._v("·缺点那？？？")]),s._v(" "),t("p",[t("img",{attrs:{src:a(1062),alt:""}}),s._v("\n缺点：")]),s._v(" "),t("p",[s._v("原来规划好的节点，进行扩容或者缩容就比较麻烦了额，不管扩缩，每次数据变动导致节点有变动，映射关系需要重新进行计算，在服务器个数固定不变时没有问题，如果需要弹性扩容或故障停机的情况下，原来的取模公式就会发生变化：Hash(key)/3 会变成 Hash(key) /?。此时地址经过取余运算的结果将发生很大变化，根据公式获取的服务器也会变得不可控。\n某个 redis 机器宕机了，由于台数数量变化，会导致 hash 取余全部数据重新洗牌。")]),s._v(" "),t("p",[s._v("·一致性哈希算法分区\n·是什么\n一致性 Hash 算法背景\n　　一致性哈希算法在 1997 年由麻省理工学院中提出的，设计目标是为了解决\n分布式缓存数据变动和映射问题，某个机器宕机了，分母数量改变了，自然取余数不 OK 了。")]),s._v(" "),t("p",[s._v("·能干嘛\n·提出一致性 Hash 解决方案。 目的是当服务器个数发生变动时， 尽量减少影响客户端到服务器的映射关系\n·3 大步骤\n·算法构建一致性哈希环")]),s._v(" "),t("p",[s._v("一致性哈希环\n    一致性哈希算法必然有个 hash 函数并按照算法产生 hash 值，这个算法的所有可能哈希值会构成一个全量集，这个集合可以成为一个 hash 空间[0,2^32-1]，这个是一个线性空间，但是在算法中，我们通过适当的逻辑控制将它首尾相连(0 = 2^32),这样让它逻辑上形成了一个环形空间。")]),s._v(" "),t("p",[s._v("它也是按照使用取模的方法，前面笔记介绍的节点取模法是对节点（服务器）的数量进行取模。而一致性 Hash 算法是对 2^32 取模，简单来说，一致性 Hash 算法将整个哈希值空间组织成一个虚拟的圆环，如假设某哈希函数 H 的值空间为 0-2^32-1（即哈希值是一个 32 位无符号整形），整个哈希环如下图：整个空间按顺时针方向组织，圆环的正上方的点代表 0，0 点右侧的第一个点代表 1，以此类推，2、3、4、……直到 2^32-1，也就是说 0 点左侧的第一个点代表 2^32-1， 0 和 2^32-1 在零点中方向重合，我们把这个由 2^32 个点组成的圆环称为 Hash 环。")]),s._v(" "),t("p",[t("img",{attrs:{src:a(1063),alt:""}})]),s._v(" "),t("p",[s._v("·服务器 IP 节点映射\n节点映射\n    将集群中各个 IP 节点映射到环上的某一个位置。\n    将各个服务器使用 Hash 进行一个哈希，具体可以选择服务器的 IP 或主机名作为关键字进行哈希，这样每台机器就能确定其在哈希环上的位置。假如 4 个节点 NodeA、B、C、D，经过 IP 地址的哈希函数计算(hash(ip))，使用 IP 地址哈希后在环空间的位置如下：")]),s._v(" "),t("p",[t("img",{attrs:{src:a(1064),alt:""}})]),s._v(" "),t("p",[s._v("·key 落到服务器的落键规则\n当我们需要存储一个 kv 键值对时，首先计算 key 的 hash 值，hash(key)，将这个 key 使用相同的函数 Hash 计算出哈希值并确定此数据在环上的位置，从此位置沿环顺时针“行走”，第一台遇到的服务器就是其应该定位到的服务器，并将该键值对存储在该节点上。\n如我们有 Object A、Object B、Object C、Object D 四个数据对象，经过哈希计算后，在环空间上的位置如下：根据一致性 Hash 算法，数据 A 会被定为到 Node A 上，B 被定为到 Node B 上，C 被定为到 Node C 上，D 被定为到 Node D 上。")]),s._v(" "),t("p",[t("img",{attrs:{src:a(1065),alt:""}})]),s._v(" "),t("p",[s._v("·优点\n·一致性哈希算法的容错性\n容错性\n假设 Node C 宕机，可以看到此时对象 A、B、D 不会受到影响，只有 C 对象被重定位到 Node D。一般的，在一致性 Hash 算法中，如果一台服务器不可用，则受影响的数据仅仅是此服务器到其环空间中前一台服务器（即沿着逆时针方向行走遇到的第一台服务器）之间数据，其它不会受到影响。简单说，就是 C 挂了，受到影响的只是 B、C 之间的数据，并且这些数据会转移到 D 进行存储。")]),s._v(" "),t("p",[t("img",{attrs:{src:a(1066),alt:""}})]),s._v(" "),t("p",[s._v("·一致性哈希算法的扩展性\n  扩展性\n数据量增加了，需要增加一台节点 NodeX，X 的位置在 A 和 B 之间，那收到影响的也就是 A 到 X 之间的数据，重新把 A 到 X 的数据录入到 X 上即可，\n不会导致 hash 取余全部数据重新洗牌。\n"),t("img",{attrs:{src:a(1067),alt:""}})]),s._v(" "),t("p",[s._v("·缺点\n·一致性哈希算法的数据倾斜问题")]),s._v(" "),t("p",[s._v("Hash 环的数据倾斜问题\n一致性 Hash 算法在服务节点太少时，容易因为节点分布不均匀而造成数据倾斜（被缓存的对象大部分集中缓存在某一台服务器上）问题，\n例如系统中只有两台服务器：")]),s._v(" "),t("p",[t("img",{attrs:{src:a(1068),alt:""}})]),s._v(" "),t("p",[s._v("·小总结\n为了在节点数目发生改变时尽可能少的迁移数据")]),s._v(" "),t("p",[s._v("将所有的存储节点排列在收尾相接的 Hash 环上，每个 key 在计算 Hash 后会顺时针找到临近的存储节点存放。\n而当有节点加入或退出时仅影响该节点在 Hash 环上顺时针相邻的后续节点。")]),s._v(" "),t("p",[s._v("优点\n加入和删除节点只影响哈希环中顺时针方向的相邻的节点，对其他节点无影响。")]),s._v(" "),t("p",[s._v("缺点  \n数据的分布和节点的位置有关，因为这些节点不是均匀的分布在哈希环上的，所以数据在进行存储时达不到均匀分布的效果。")]),s._v(" "),t("p",[s._v("·哈希槽分区\n·是什么")]),s._v(" "),t("p",[s._v("1 为什么出现")]),s._v(" "),t("p",[t("img",{attrs:{src:a(1069),alt:""}})]),s._v(" "),t("p",[s._v("哈希槽实质就是一个数组，数组[0,2^14 -1]形成 hash slot 空间。")]),s._v(" "),t("p",[s._v("2 能干什么\n解决均匀分配的问题，在数据和节点之间又加入了一层，把这层称为哈希槽（slot），用于管理数据和节点之间的关系，现在就相当于节点上放的是槽，槽里放的是数据。")]),s._v(" "),t("p",[t("img",{attrs:{src:a(1070),alt:""}})]),s._v(" "),t("p",[s._v("槽解决的是粒度问题，相当于把粒度变大了，这样便于数据移动。\n哈希解决的是映射问题，使用 key 的哈希值来计算所在的槽，便于数据分配。")]),s._v(" "),t("p",[s._v("3 多少个 hash 槽\n一个集群只能有 16384 个槽，编号 0-16383（0-2^14-1）。这些槽会分配给集群中的所有主节点，\n分配策略没有要求。可以指定哪些编号的槽分配给哪个主节点。集群会记录节点和槽的对应关系。解决了节点和槽的关系后，接下来就需要对 key 求哈希值，然后对 16384 取余，余数是几 key 就落入对应的槽里。slot = CRC16(key) % 16384。以槽为单位移动数据，因为槽的数目是固定的，处理起来比较容易，这样数据移动问题就解决了。")]),s._v(" "),t("p",[s._v("·哈希槽计算")]),s._v(" "),t("p",[s._v("Redis 集群中内置了 16384 个哈希槽，redis 会根据节点数量大致均等的将哈希槽映射到不同的节点。当需要在 Redis 集群中放置一个 key-value 时，redis 先对 key 使用 crc16 算法算出一个结果，然后把结果对 16384 求余数，这样每个 key 都会对应一个编号在 0-16383 之间的哈希槽，也就是映射到某个节点上。如下代码，key 之 A 、B 在 Node2， key 之 C 落在 Node3 上")]),s._v(" "),t("p",[t("img",{attrs:{src:a(1071),alt:""}})]),s._v(" "),t("p",[s._v("·3 主 3 从 redis 集群扩缩容配置案例架构说明\n·见自己的 processon 笔记\n·开打步骤\n·3 主 3 从 redis 集群配置\n·关闭防火墙+启动 docker 后台服务")]),s._v(" "),t("p",[t("img",{attrs:{src:a(1072),alt:""}})]),s._v(" "),t("p",[s._v("·systemctl start docker\n·新建 6 个 docker 容器 redis 实例\ndocker run -d --name redis-node-1 --net host --privileged=true -v /data/redis/share/redis-node-1:/data redis:6.0.8 --cluster-enabled yes --appendonly yes --port 6381")]),s._v(" "),t("p",[s._v("docker run -d --name redis-node-2 --net host --privileged=true -v /data/redis/share/redis-node-2:/data redis:6.0.8 --cluster-enabled yes --appendonly yes --port 6382")]),s._v(" "),t("p",[s._v("docker run -d --name redis-node-3 --net host --privileged=true -v /data/redis/share/redis-node-3:/data redis:6.0.8 --cluster-enabled yes --appendonly yes --port 6383")]),s._v(" "),t("p",[s._v("docker run -d --name redis-node-4 --net host --privileged=true -v /data/redis/share/redis-node-4:/data redis:6.0.8 --cluster-enabled yes --appendonly yes --port 6384")]),s._v(" "),t("p",[s._v("docker run -d --name redis-node-5 --net host --privileged=true -v /data/redis/share/redis-node-5:/data redis:6.0.8 --cluster-enabled yes --appendonly yes --port 6385")]),s._v(" "),t("p",[s._v("docker run -d --name redis-node-6 --net host --privileged=true -v /data/redis/share/redis-node-6:/data redis:6.0.8 --cluster-enabled yes --appendonly yes --port 6386")]),s._v(" "),t("p",[s._v("如果运行成功，效果如下:\n"),t("img",{attrs:{src:a(1073),alt:""}})]),s._v(" "),t("p",[s._v("·命令分步解释\n·docker run\n·创建并运行 docker 容器实例\n·--name redis-node-6\n·容器名字\n·--net host\n·使用宿主机的 IP 和端口，默认\n·--privileged=true\n·获取宿主机 root 用户权限\n·-v /data/redis/share/redis-node-6:/data\n·容器卷，宿主机地址:docker 内部地址\n·redis:6.0.8\n·redis 镜像和版本号\n·--cluster-enabled yes\n·开启 redis 集群\n·--appendonly yes\n·开启持久化\n·--port 6386\n·redis 端口号\n·进入容器 redis-node-1 并为 6 台机器构建集群关系\n·进入容器\n·docker exec -it redis-node-1 /bin/bash\n·构建主从关系")]),s._v(" "),t("p",[s._v("//注意，进入 docker 容器后才能执行一下命令，且注意自己的真实 IP 地址")]),s._v(" "),t("p",[s._v("redis-cli --cluster create 192.168.111.147:6381 192.168.111.147:6382 192.168.111.147:6383 192.168.111.147:6384 192.168.111.147:6385 192.168.111.147:6386 --cluster-replicas 1")]),s._v(" "),t("p",[s._v("--cluster-replicas 1 表示为每个 master 创建一个 slave 节点")]),s._v(" "),t("p",[t("img",{attrs:{src:a(1074),alt:""}})]),s._v(" "),t("p",[t("img",{attrs:{src:a(1075),alt:""}})]),s._v(" "),t("p",[s._v("·一切 OK 的话，3 主 3 从搞定\n·链接进入 6381 作为切入点，查看集群状态\n·链接进入 6381 作为切入点，查看节点状态")]),s._v(" "),t("p",[t("img",{attrs:{src:a(1076),alt:""}})]),s._v(" "),t("p",[t("img",{attrs:{src:a(1077),alt:""}})]),s._v(" "),t("p",[s._v("·cluster info\n·cluster nodes\n·主从容错切换迁移案例\n·数据读写存储\n·启动 6 机构成的集群并通过 exec 进入\n·对 6381 新增两个 key\n·防止路由失效加参数-c 并新增两个 key")]),s._v(" "),t("p",[t("img",{attrs:{src:a(1078),alt:""}})]),s._v(" "),t("p",[s._v("加入参数-c，优化路由")]),s._v(" "),t("p",[t("img",{attrs:{src:a(1079),alt:""}})]),s._v(" "),t("p",[s._v("·查看集群信息")]),s._v(" "),t("div",{staticClass:"language-bash line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-bash"}},[t("code",[s._v("redis-cli "),t("span",{pre:!0,attrs:{class:"token parameter variable"}},[s._v("--cluster")]),s._v(" check "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("192.168")]),s._v(".111.147:6381\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br")])]),t("p",[t("img",{attrs:{src:a(1080),alt:""}})]),s._v(" "),t("p",[s._v("·容错切换迁移\n·主 6381 和从机切换，先停止主机 6381\n·6381 主机停了，对应的真实从机上位\n·6381 作为 1 号主机分配的从机以实际情况为准，具体是几号机器就是几号\n·再次查看集群信息")]),s._v(" "),t("p",[t("img",{attrs:{src:a(1081),alt:""}})]),s._v(" "),t("p",[s._v("6381 宕机了，6385 上位成为了新的 master。\n备注：本次脑图笔记 6381 为主下面挂从 6385。\n每次案例下面挂的从机以实际情况为准，具体是几号机器就是几号")]),s._v(" "),t("p",[s._v("·先还原之前的 3 主 3 从")]),s._v(" "),t("p",[t("img",{attrs:{src:a(1082),alt:""}})]),s._v(" "),t("p",[s._v("中间需要等待一会儿，docker 集群重新响应。")]),s._v(" "),t("p",[s._v("·先启 6381")]),s._v(" "),t("p",[t("img",{attrs:{src:a(1083),alt:""}})]),s._v(" "),t("p",[s._v("·docker start redis-node-1\n·再停 6385")]),s._v(" "),t("p",[t("img",{attrs:{src:a(1084),alt:""}})]),s._v(" "),t("p",[s._v("·docker stop redis-node-5\n·再启 6385")]),s._v(" "),t("p",[t("img",{attrs:{src:a(1085),alt:""}})]),s._v(" "),t("p",[s._v("·docker start redis-node-5\n·主从机器分配情况以实际情况为准\n·查看集群状态\n·redis-cli --cluster check 自己 IP:6381")]),s._v(" "),t("p",[t("img",{attrs:{src:a(1086),alt:""}})]),s._v(" "),t("p",[s._v("·主从扩容案例\n·新建 6387、6388 两个节点+新建后启动+查看是否 8 节点")]),s._v(" "),t("div",{staticClass:"language-bash line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-bash"}},[t("code",[t("span",{pre:!0,attrs:{class:"token function"}},[s._v("docker")]),s._v(" run "),t("span",{pre:!0,attrs:{class:"token parameter variable"}},[s._v("-d")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token parameter variable"}},[s._v("--name")]),s._v(" redis-node-7 "),t("span",{pre:!0,attrs:{class:"token parameter variable"}},[s._v("--net")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("host")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token parameter variable"}},[s._v("--privileged")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("true "),t("span",{pre:!0,attrs:{class:"token parameter variable"}},[s._v("-v")]),s._v(" /data/redis/share/redis-node-7:/data redis:6.0.8 --cluster-enabled "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("yes")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token parameter variable"}},[s._v("--appendonly")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("yes")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token parameter variable"}},[s._v("--port")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("6387")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br")])]),t("div",{staticClass:"language-bash line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-bash"}},[t("code",[t("span",{pre:!0,attrs:{class:"token function"}},[s._v("docker")]),s._v(" run "),t("span",{pre:!0,attrs:{class:"token parameter variable"}},[s._v("-d")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token parameter variable"}},[s._v("--name")]),s._v(" redis-node-8 "),t("span",{pre:!0,attrs:{class:"token parameter variable"}},[s._v("--net")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("host")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token parameter variable"}},[s._v("--privileged")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("true "),t("span",{pre:!0,attrs:{class:"token parameter variable"}},[s._v("-v")]),s._v(" /data/redis/share/redis-node-8:/data redis:6.0.8 --cluster-enabled "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("yes")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token parameter variable"}},[s._v("--appendonly")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("yes")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token parameter variable"}},[s._v("--port")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("6388")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br")])]),t("div",{staticClass:"language-bash line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-bash"}},[t("code",[t("span",{pre:!0,attrs:{class:"token function"}},[s._v("docker")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("ps")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br")])]),t("p",[s._v("·进入 6387 容器实例内部\n·docker exec -it redis-node-7 /bin/bash\n·将新增的 6387 节点(空槽号)作为 master 节点加入原集群")]),s._v(" "),t("p",[s._v("将新增的 6387 作为 master 节点加入集群\nredis-cli --cluster add-node  自己实际 IP 地址:6387 自己实际 IP 地址:6381\n6387 就是将要作为 master 新增节点\n6381 就是原来集群节点里面的领路人，相当于 6387 拜拜 6381 的码头从而找到组织加入集群")]),s._v(" "),t("p",[t("img",{attrs:{src:a(1087),alt:""}})]),s._v(" "),t("p",[s._v("·检查集群情况第 1 次\nredis-cli --cluster check 真实 ip 地址:6381")]),s._v(" "),t("p",[t("img",{attrs:{src:a(1088),alt:""}})]),s._v(" "),t("p",[t("img",{attrs:{src:a(1089),alt:""}})]),s._v(" "),t("p",[s._v("·重新分派槽号")]),s._v(" "),t("p",[s._v("重新分派槽号\n命令:redis-cli --cluster reshard IP 地址:端口号\nredis-cli --cluster reshard 192.168.111.147:6381")]),s._v(" "),t("p",[t("img",{attrs:{src:a(1090),alt:""}})]),s._v(" "),t("p",[s._v("·检查集群情况第 2 次")]),s._v(" "),t("p",[s._v("redis-cli --cluster check 真实 ip 地址:6381")]),s._v(" "),t("p",[t("img",{attrs:{src:a(1091),alt:""}})]),s._v(" "),t("p",[s._v("·槽号分派说明")]),s._v(" "),t("p",[s._v("为什么 6387 是 3 个新的区间，以前的还是连续？\n重新分配成本太高，所以前 3 家各自匀出来一部分，从 6381/6382/6383 三个旧节点分别匀出 1364 个坑位给新节点 6387")]),s._v(" "),t("p",[t("img",{attrs:{src:a(1092),alt:""}})]),s._v(" "),t("p",[s._v("·为主节点 6387 分配从节点 6388")]),s._v(" "),t("p",[s._v("命令：redis-cli --cluster add-node ip:新 slave 端口 ip:新 master 端口 --cluster-slave --cluster-master-id 新主机节点 ID")]),s._v(" "),t("p",[s._v("redis-cli --cluster add-node 192.168.111.147:6388 192.168.111.147:6387 --cluster-slave --cluster-master-id e4781f644d4a4e4d4b4d107157b9ba8144631451-------这个是 6387 的编号，按照自己实际情况")]),s._v(" "),t("p",[t("img",{attrs:{src:a(1093),alt:""}})]),s._v(" "),t("p",[s._v("·检查集群情况第 3 次")]),s._v(" "),t("p",[s._v("redis-cli --cluster check 192.168.111.147:6382")]),s._v(" "),t("p",[t("img",{attrs:{src:a(1094),alt:""}})]),s._v(" "),t("p",[s._v("·主从缩容案例\n·目的：6387 和 6388 下线\n·检查集群情况 1 获得 6388 的节点 ID")]),s._v(" "),t("p",[s._v("redis-cli --cluster check 192.168.111.147:6382")]),s._v(" "),t("p",[t("img",{attrs:{src:a(1095),alt:""}})]),s._v(" "),t("p",[s._v("·将 6388 删除 从集群中将 4 号从节点 6388 删除")]),s._v(" "),t("p",[s._v("命令：redis-cli --cluster del-node ip:从机端口 从机 6388 节点 ID")]),s._v(" "),t("p",[s._v("redis-cli --cluster del-node 192.168.111.147:6388 5d149074b7e57b802287d1797a874ed7a1a284a8")]),s._v(" "),t("p",[t("img",{attrs:{src:a(1096),alt:""}})]),s._v(" "),t("p",[s._v("redis-cli --cluster check 192.168.111.147:6382")]),s._v(" "),t("p",[s._v("检查一下发现，6388 被删除了，只剩下 7 台机器了。")]),s._v(" "),t("p",[t("img",{attrs:{src:a(1097),alt:""}})]),s._v(" "),t("p",[s._v("·将 6387 的槽号清空，重新分配，本例将清出来的槽号都给 6381")]),s._v(" "),t("p",[s._v("redis-cli --cluster reshard 192.168.111.147:6381")]),s._v(" "),t("p",[t("img",{attrs:{src:a(1098),alt:""}})]),s._v(" "),t("p",[s._v("·检查集群情况第二次")]),s._v(" "),t("p",[s._v("redis-cli --cluster check 192.168.111.147:6381")]),s._v(" "),t("p",[s._v("4096 个槽位都指给 6381，它变成了 8192 个槽位，相当于全部都给 6381 了，不然要输入 3 次，一锅端")]),s._v(" "),t("p",[t("img",{attrs:{src:a(1099),alt:""}}),s._v("\n·将 6387 删除")]),s._v(" "),t("p",[s._v("命令：redis-cli --cluster del-node ip:端口 6387 节点 ID")]),s._v(" "),t("p",[s._v("redis-cli --cluster del-node 192.168.111.147:6387 e4781f644d4a4e4d4b4d107157b9ba8144631451")]),s._v(" "),t("p",[t("img",{attrs:{src:a(1100),alt:""}})]),s._v(" "),t("p",[s._v("·检查集群情况第三次")]),s._v(" "),t("p",[s._v("redis-cli --cluster check 192.168.111.147:6381")]),s._v(" "),t("p",[t("img",{attrs:{src:a(1101),alt:""}})])])}),[],!1,null,null,null);e.default=r.exports}}]);